{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "***\n",
    "Student: Anton Avramov <lukav@lukav.com>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=6):\n",
    "    \"\"\"\n",
    "    This function finds the lines, avarage and extrapolate them\n",
    "    \"\"\"\n",
    "    right_lines = []\n",
    "    left_lines = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            #Find the slope and push eigher in left or right list\n",
    "            slope = ((y2-y1)/(x2-x1))\n",
    "            if slope < -0.2:\n",
    "                right_lines.append(line)\n",
    "            elif slope > 0.2:\n",
    "                left_lines.append(line)\n",
    "    imshape = img.shape\n",
    "    top = np.int(img.shape[0]*0.6)\n",
    "    bottom = img.shape[0]\n",
    "    # if we have found lines then we call process_lines for either left or write\n",
    "    if left_lines:\n",
    "        left_line = process_line(left_lines, top, bottom)\n",
    "        cv2.line(img, (left_line[0], left_line[1]), (left_line[2], left_line[3]), color, thickness)\n",
    "\n",
    "    if right_lines:\n",
    "        right_line = process_line(right_lines, top, bottom)\n",
    "        cv2.line(img, (right_line[0], right_line[1]), (right_line[2], right_line[3]), color, thickness)\n",
    "    \n",
    "def process_line(lines, top, bottom):\n",
    "    \"\"\"\n",
    "    Process a list of lines and returns one avarage line extrapolated between top and bottom y axe\n",
    "    \"\"\"\n",
    "    #Find and avarage\n",
    "    avg = np.mean(lines, axis=0, dtype=int)\n",
    "    avg = avg[0]\n",
    "    # Find the slope and the intercept of the vector\n",
    "    slope = ((avg[3] - avg[1]) / (avg[2] - avg[0]))\n",
    "    intercept = avg[1] - (slope * avg[0])\n",
    "    # calculate the x using the slope and intercept for top and bottom y\n",
    "    x1 = np.int((top - intercept) / slope)\n",
    "    y1 = top\n",
    "    x2 = np.int((bottom - intercept) / slope)\n",
    "    y2 = bottom\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def color_mask(image):\n",
    "    \"\"\"Apply a color mask to get white and yellow lines\"\"\"\n",
    "    # define range of white color\n",
    "    lower = np.array([150,150,0])\n",
    "    upper = np.array([255,255,255])\n",
    "    \n",
    "    # Threshold the HSV image to get only white/yellow colors\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(image,image, mask= mask)\n",
    "    \n",
    "    return res\n",
    "\n",
    "# My pipeline function\n",
    "def pipeline(image):\n",
    "    \"\"\"The pipeline function to use all the techniques\"\"\"\n",
    "    #Get only white and yellow\n",
    "    masked = color_mask(image)\n",
    "\n",
    "    #grayscale the image\n",
    "    gray = grayscale(masked)\n",
    "    \n",
    "    #Gaussian smooth\n",
    "    blur_gray = gaussian_blur(gray,5)\n",
    "    \n",
    "    #canny\n",
    "    edges = canny(blur_gray, 200, 250)\n",
    "    \n",
    "    #Get only the region of interest\n",
    "    imshape = image.shape\n",
    "    int_height = np.int(image.shape[0]*0.6)\n",
    "    int_width = np.int(image.shape[1]*0.47)\n",
    "    vertices = np.array([[(0,imshape[0]),(int_width, int_height), (image.shape[1]-int_width, int_height), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    int_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "    #Find the lines\n",
    "    lines_img = hough_lines(int_edges, 1, np.pi/180, 20, 20, 50)\n",
    "    return weighted_img(lines_img, image)\n",
    "\n",
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "\n",
    "    return pipeline(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Images\n",
    "\n",
    "Create directories and tries all the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "ensure_dir(\"test_images_output/\")\n",
    "ensure_dir(\"test_videos_output/\")\n",
    "\n",
    "for file in os.listdir(\"test_images/\"):\n",
    "    image = mpimg.imread('test_images/' + file)\n",
    "    processed = pipeline(image)\n",
    "    plt.imsave('test_images_output/' + file, processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 5/222 [00:00<00:04, 49.35it/s]\u001b[A\n",
      "  5%|▍         | 11/222 [00:00<00:04, 49.54it/s]\u001b[A\n",
      "  8%|▊         | 17/222 [00:00<00:04, 50.83it/s]\u001b[A\n",
      " 10%|█         | 23/222 [00:00<00:03, 52.38it/s]\u001b[A\n",
      " 13%|█▎        | 28/222 [00:00<00:03, 51.60it/s]\u001b[A\n",
      " 15%|█▌        | 34/222 [00:00<00:03, 52.28it/s]\u001b[A\n",
      " 18%|█▊        | 40/222 [00:00<00:03, 52.66it/s]\u001b[A\n",
      " 21%|██        | 46/222 [00:00<00:03, 52.52it/s]\u001b[A\n",
      " 23%|██▎       | 51/222 [00:01<00:04, 38.88it/s]\u001b[A\n",
      " 25%|██▌       | 56/222 [00:01<00:04, 38.39it/s]\u001b[A\n",
      " 27%|██▋       | 61/222 [00:01<00:04, 37.80it/s]\u001b[A\n",
      " 29%|██▉       | 65/222 [00:01<00:04, 38.04it/s]\u001b[A\n",
      " 31%|███       | 69/222 [00:01<00:04, 37.32it/s]\u001b[A\n",
      " 33%|███▎      | 73/222 [00:01<00:04, 36.71it/s]\u001b[A\n",
      " 35%|███▍      | 77/222 [00:01<00:04, 35.32it/s]\u001b[A\n",
      " 37%|███▋      | 82/222 [00:01<00:03, 36.91it/s]\u001b[A\n",
      " 39%|███▉      | 87/222 [00:02<00:03, 37.96it/s]\u001b[A\n",
      " 41%|████▏     | 92/222 [00:02<00:03, 38.20it/s]\u001b[A\n",
      " 43%|████▎     | 96/222 [00:02<00:03, 37.56it/s]\u001b[A\n",
      " 45%|████▌     | 100/222 [00:02<00:03, 35.96it/s]\u001b[A\n",
      " 47%|████▋     | 104/222 [00:02<00:03, 35.64it/s]\u001b[A\n",
      " 49%|████▉     | 109/222 [00:02<00:03, 36.38it/s]\u001b[A\n",
      " 51%|█████     | 113/222 [00:02<00:03, 34.28it/s]\u001b[A\n",
      " 53%|█████▎    | 117/222 [00:02<00:03, 33.88it/s]\u001b[A\n",
      " 55%|█████▍    | 121/222 [00:03<00:02, 34.42it/s]\u001b[A\n",
      " 56%|█████▋    | 125/222 [00:03<00:02, 34.21it/s]\u001b[A\n",
      " 58%|█████▊    | 129/222 [00:03<00:02, 32.89it/s]\u001b[A\n",
      " 60%|█████▉    | 133/222 [00:03<00:02, 33.75it/s]\u001b[A\n",
      " 62%|██████▏   | 137/222 [00:03<00:02, 35.36it/s]\u001b[A\n",
      " 64%|██████▎   | 141/222 [00:03<00:02, 35.70it/s]\u001b[A\n",
      " 65%|██████▌   | 145/222 [00:03<00:02, 35.25it/s]\u001b[A\n",
      " 67%|██████▋   | 149/222 [00:03<00:02, 33.84it/s]\u001b[A\n",
      "100%|█████████▉| 221/222 [00:05<00:00, 38.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 9.29 s, sys: 324 ms, total: 9.61 s\n",
      "Wall time: 6.46 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:16<00:00, 41.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 28.4 s, sys: 784 ms, total: 29.2 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:11<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 14.5 s, sys: 488 ms, total: 14.9 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
